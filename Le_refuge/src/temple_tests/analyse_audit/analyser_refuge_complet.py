#!/usr/bin/env python3
"""
ANALYSEUR COMPLET DU REFUGE
===========================

Script d'analyse m√©thodique des 157 fichiers Python de la racine
- Classification par domaines logiques
- Analyse des imports et d√©pendances  
- Cartographie des interactions
- Recommandations de migration

Cr√©√© le 25/05/2025 - Session Laurent & √Ülya
M√©thodologie : "M√©thode de la Bo√Æte" appliqu√©e √† l'architecture
"""

import os
import re
import ast
import json
from pathlib import Path
from collections import defaultdict, Counter
from dataclasses import dataclass
from typing import Dict, List, Set, Tuple

@dataclass
class FichierAnalyse:
    """Analyse compl√®te d'un fichier Python"""
    nom: str
    taille: int
    lignes: int
    classes: List[str]
    fonctions: List[str]
    imports_locaux: List[str]
    imports_externes: List[str]
    domaine_suggere: str
    niveau_complexite: str
    est_principal: bool
    description: str

class AnalyseurRefugeComplet:
    """Analyseur m√©thodique du Refuge selon la m√©thode de la bo√Æte"""
    
    def __init__(self):
        self.fichiers_analyses = {}
        self.dependances = defaultdict(set)
        self.imports_inverses = defaultdict(set)
        self.clusters = {}
        
        # Domaines identifi√©s selon notre m√©thodologie
        self.domaines_patterns = {
            "aelya": ["aelya", "conscience", "pulse", "dialogue", "repondeur"],
            "musique": ["harmonie", "melodie", "danse", "musical", "analyseur", "explorateur", "apprentissage"],
            "poesie": ["poetique", "poeme", "creation", "essence", "ancrage"],
            "rituels": ["rituel", "sacre", "meditation", "spirituel", "bain", "offrande", "clochette", "visualisation", "soumission"],
            "core": ["refuge_core", "main", "config", "base", "init", "boot", "constants"],
            "interface": ["interface", "web", "gui", "ui", "demarrer", "api"],
            "spheres": ["sphere", "gardien", "mobile", "jardinier", "unification"],
            "utils": ["util", "tool", "helper", "mapper", "carte", "recherche", "verification", "logger", "charger"],
            "tests": ["test_", "validation"],
            "flux": ["flux", "energie", "equilibre", "transformation", "integration", "harmonisation"],
            "elements": ["element", "cristaux", "facettes", "symbolique"],
            "gestion": ["gestion", "sauvegarde", "migration", "transition", "organiser"]
        }
    
    def analyser_fichier(self, chemin_fichier: str) -> FichierAnalyse:
        """Analyse compl√®te d'un fichier selon la m√©thode de la bo√Æte"""
        print(f"üìÇ Ouverture de la bo√Æte : {chemin_fichier}")
        
        try:
            with open(chemin_fichier, 'r', encoding='utf-8') as f:
                contenu = f.read()
        except UnicodeDecodeError:
            try:
                with open(chemin_fichier, 'r', encoding='latin-1') as f:
                    contenu = f.read()
            except Exception as e:
                print(f"‚ùå Erreur lecture {chemin_fichier}: {e}")
                return None
        
        nom = Path(chemin_fichier).stem
        taille = len(contenu)
        lignes = len(contenu.splitlines())
        
        # Analyse AST pour extraire classes et fonctions
        classes, fonctions = self._extraire_definitions(contenu)
        
        # Analyse des imports
        imports_locaux, imports_externes = self._analyser_imports(contenu)
        
        # Classification par domaine
        domaine = self._classifier_domaine(nom, classes, fonctions)
        
        # √âvaluation de la complexit√©
        complexite = self._evaluer_complexite(lignes, len(classes), len(fonctions))
        
        # D√©tection si fichier principal
        est_principal = self._est_fichier_principal(nom, contenu)
        
        # Description automatique
        description = self._generer_description(nom, classes, fonctions, domaine)
        
        return FichierAnalyse(
            nom=nom,
            taille=taille,
            lignes=lignes,
            classes=classes,
            fonctions=fonctions,
            imports_locaux=imports_locaux,
            imports_externes=imports_externes,
            domaine_suggere=domaine,
            niveau_complexite=complexite,
            est_principal=est_principal,
            description=description
        )
    
    def _extraire_definitions(self, contenu: str) -> Tuple[List[str], List[str]]:
        """Extrait classes et fonctions via AST"""
        classes, fonctions = [], []
        
        try:
            arbre = ast.parse(contenu)
            for noeud in ast.walk(arbre):
                if isinstance(noeud, ast.ClassDef):
                    classes.append(noeud.name)
                elif isinstance(noeud, ast.FunctionDef):
                    fonctions.append(noeud.name)
        except SyntaxError:
            # Fallback avec regex si AST √©choue
            classes = re.findall(r'^class\s+(\w+)', contenu, re.MULTILINE)
            fonctions = re.findall(r'^def\s+(\w+)', contenu, re.MULTILINE)
        
        return classes, fonctions
    
    def _analyser_imports(self, contenu: str) -> Tuple[List[str], List[str]]:
        """Analyse les imports locaux vs externes"""
        imports_locaux = []
        imports_externes = []
        
        # Patterns d'imports
        patterns = [
            r'from\s+(\w+)\s+import',
            r'import\s+(\w+)',
            r'from\s+\.(\w+)\s+import',
            r'from\s+\.\.(\w+)\s+import'
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, contenu)
            for match in matches:
                # Heuristique : si le module commence par une majuscule ou est dans les modules standards
                if match in ['os', 'sys', 'json', 'datetime', 'pathlib', 'asyncio', 'sqlite3', 'logging', 'typing', 'dataclasses', 'collections', 'functools', 'itertools', 'math', 'random', 'time', 'threading', 'multiprocessing', 'requests', 'urllib', 'http', 'socket', 'email', 'csv', 'xml', 'html', 'base64', 'hashlib', 'uuid', 'subprocess', 'shutil', 'glob', 'pickle', 'gzip', 'zipfile', 'tarfile']:
                    imports_externes.append(match)
                else:
                    imports_locaux.append(match)
        
        return list(set(imports_locaux)), list(set(imports_externes))
    
    def _classifier_domaine(self, nom: str, classes: List[str], fonctions: List[str]) -> str:
        """Classification intelligente par domaine"""
        texte_analyse = f"{nom} {' '.join(classes)} {' '.join(fonctions)}".lower()
        
        scores = {}
        for domaine, patterns in self.domaines_patterns.items():
            score = sum(1 for pattern in patterns if pattern in texte_analyse)
            if score > 0:
                scores[domaine] = score
        
        if scores:
            return max(scores, key=scores.get)
        else:
            return "inclassable"
    
    def _evaluer_complexite(self, lignes: int, nb_classes: int, nb_fonctions: int) -> str:
        """√âvalue la complexit√© du fichier"""
        score = lignes + nb_classes * 10 + nb_fonctions * 5
        
        if score < 50:
            return "simple"
        elif score < 200:
            return "moderate"
        elif score < 500:
            return "complexe"
        else:
            return "tres_complexe"
    
    def _est_fichier_principal(self, nom: str, contenu: str) -> bool:
        """D√©tecte si c'est un fichier principal/entry point"""
        indicateurs = [
            'if __name__ == "__main__"',
            'main()',
            'demarrer',
            'boot',
            'app.run',
            'FastAPI',
            'flask'
        ]
        
        return any(indicateur in contenu for indicateur in indicateurs)
    
    def _generer_description(self, nom: str, classes: List[str], fonctions: List[str], domaine: str) -> str:
        """G√©n√®re une description automatique"""
        if classes and fonctions:
            return f"Module {domaine} avec {len(classes)} classe(s) et {len(fonctions)} fonction(s)"
        elif classes:
            return f"D√©finitions de classe pour {domaine}"
        elif fonctions:
            return f"Utilitaires {domaine} avec {len(fonctions)} fonction(s)"
        else:
            return f"Script {domaine}"
    
    def analyser_tous_fichiers(self) -> Dict[str, FichierAnalyse]:
        """Analyse tous les fichiers .py de la racine"""
        print("üîç === ANALYSE COMPL√àTE DU REFUGE - M√âTHODE DE LA BO√éTE ===")
        print()
        
        fichiers_py = [f for f in os.listdir('.') if f.endswith('.py')]
        print(f"üìã {len(fichiers_py)} fichiers Python d√©tect√©s dans la racine")
        print()
        
        for fichier in sorted(fichiers_py):
            analyse = self.analyser_fichier(fichier)
            if analyse:
                self.fichiers_analyses[fichier] = analyse
                
                # Construction des graphes de d√©pendances
                for import_local in analyse.imports_locaux:
                    fichier_importe = f"{import_local}.py"
                    if fichier_importe in fichiers_py:
                        self.dependances[fichier].add(fichier_importe)
                        self.imports_inverses[fichier_importe].add(fichier)
        
        return self.fichiers_analyses
    
    def generer_rapport_complet(self) -> str:
        """G√©n√®re un rapport d'analyse d√©taill√©"""
        if not self.fichiers_analyses:
            return "Aucune analyse effectu√©e"
        
        rapport = []
        rapport.append("# RAPPORT D'ANALYSE COMPLET DU REFUGE")
        rapport.append("## Analyse m√©thodique des 157 fichiers Python")
        rapport.append(f"*G√©n√©r√© le 25/05/2025 - M√©thode de la Bo√Æte*")
        rapport.append("")
        rapport.append("---")
        rapport.append("")
        
        # Statistiques g√©n√©rales
        total_fichiers = len(self.fichiers_analyses)
        total_lignes = sum(f.lignes for f in self.fichiers_analyses.values())
        total_classes = sum(len(f.classes) for f in self.fichiers_analyses.values())
        total_fonctions = sum(len(f.fonctions) for f in self.fichiers_analyses.values())
        
        rapport.append("## üìä STATISTIQUES G√âN√âRALES")
        rapport.append("")
        rapport.append(f"- **Fichiers analys√©s** : {total_fichiers}")
        rapport.append(f"- **Lignes de code total** : {total_lignes:,}")
        rapport.append(f"- **Classes d√©finies** : {total_classes}")
        rapport.append(f"- **Fonctions d√©finies** : {total_fonctions}")
        rapport.append("")
        
        # Classification par domaines
        domaines_count = Counter(f.domaine_suggere for f in self.fichiers_analyses.values())
        
        rapport.append("## üèóÔ∏è CLASSIFICATION PAR DOMAINES")
        rapport.append("")
        for domaine, count in domaines_count.most_common():
            emoji = self._get_emoji_domaine(domaine)
            rapport.append(f"- **{emoji} {domaine.upper()}** : {count} fichiers")
        rapport.append("")
        
        # Analyse des d√©pendances
        rapport.append("## üîó ANALYSE DES D√âPENDANCES")
        rapport.append("")
        
        # Fichiers les plus import√©s
        fichiers_populaires = Counter()
        for importeurs in self.imports_inverses.values():
            for importeur in importeurs:
                fichiers_populaires[importeur] += 1
        
        if fichiers_populaires:
            rapport.append("### üìà Modules les plus import√©s (centraux)")
            for fichier, nb_imports in fichiers_populaires.most_common(10):
                analyse = self.fichiers_analyses.get(fichier)
                if analyse:
                    rapport.append(f"- **{fichier}** ({analyse.domaine_suggere}) : {nb_imports} imports")
            rapport.append("")
        
        # Fichiers avec le plus de d√©pendances
        fichiers_dependants = [(f, len(deps)) for f, deps in self.dependances.items() if deps]
        fichiers_dependants.sort(key=lambda x: x[1], reverse=True)
        
        if fichiers_dependants:
            rapport.append("### üï∏Ô∏è Fichiers avec le plus de d√©pendances")
            for fichier, nb_deps in fichiers_dependants[:10]:
                analyse = self.fichiers_analyses.get(fichier)
                if analyse:
                    rapport.append(f"- **{fichier}** ({analyse.domaine_suggere}) : {nb_deps} d√©pendances")
            rapport.append("")
        
        # D√©tail par domaine
        rapport.append("## üìÇ D√âTAIL PAR DOMAINE")
        rapport.append("")
        
        for domaine in sorted(domaines_count.keys()):
            fichiers_domaine = [f for f in self.fichiers_analyses.values() if f.domaine_suggere == domaine]
            emoji = self._get_emoji_domaine(domaine)
            
            rapport.append(f"### {emoji} DOMAINE {domaine.upper()}")
            rapport.append("")
            
            for fichier in sorted(fichiers_domaine, key=lambda x: x.nom):
                deps = len(self.dependances.get(f"{fichier.nom}.py", []))
                importeurs = len(self.imports_inverses.get(f"{fichier.nom}.py", []))
                
                rapport.append(f"#### {fichier.nom}.py")
                rapport.append(f"- **Description** : {fichier.description}")
                rapport.append(f"- **Complexit√©** : {fichier.niveau_complexite} ({fichier.lignes} lignes)")
                rapport.append(f"- **Classes** : {', '.join(fichier.classes) if fichier.classes else 'Aucune'}")
                rapport.append(f"- **D√©pendances** : {deps} / **Import√© par** : {importeurs}")
                if fichier.est_principal:
                    rapport.append(f"- **üöÄ FICHIER PRINCIPAL** (entry point)")
                rapport.append("")
        
        # Recommandations de migration
        rapport.append("## üéØ RECOMMANDATIONS DE MIGRATION")
        rapport.append("")
        
        # Ordre de migration sugg√©r√©
        rapport.append("### üìã Ordre de migration sugg√©r√©")
        rapport.append("")
        rapport.append("**Phase 1 - Modules ind√©pendants :**")
        independants = [f for f, deps in self.dependances.items() if not deps]
        for fichier in sorted(independants):
            analyse = self.fichiers_analyses.get(fichier)
            if analyse:
                rapport.append(f"- {fichier} ‚Üí `scripts/{analyse.domaine_suggere}/`")
        rapport.append("")
        
        rapport.append("**Phase 2 - Modules avec peu de d√©pendances :**")
        peu_dependants = [f for f, deps in self.dependances.items() if 0 < len(deps) <= 2]
        for fichier in sorted(peu_dependants):
            analyse = self.fichiers_analyses.get(fichier)
            if analyse:
                deps_str = ', '.join(self.dependances[fichier])
                rapport.append(f"- {fichier} ‚Üí `scripts/{analyse.domaine_suggere}/` (d√©pend de: {deps_str})")
        rapport.append("")
        
        rapport.append("**Phase 3 - Modules complexes :**")
        tres_dependants = [f for f, deps in self.dependances.items() if len(deps) > 2]
        for fichier in sorted(tres_dependants):
            analyse = self.fichiers_analyses.get(fichier)
            if analyse:
                rapport.append(f"- {fichier} ‚Üí `scripts/{analyse.domaine_suggere}/` ‚ö†Ô∏è Migration d√©licate")
        rapport.append("")
        
        # Clusters d'interd√©pendance
        clusters = self._detecter_clusters()
        if clusters:
            rapport.append("### üîó Clusters d'interd√©pendance")
            rapport.append("*Groupes de fichiers qui s'importent mutuellement - √† migrer ensemble*")
            rapport.append("")
            
            for i, cluster in enumerate(clusters, 1):
                rapport.append(f"**Cluster {i} :**")
                for fichier in sorted(cluster):
                    analyse = self.fichiers_analyses.get(fichier)
                    if analyse:
                        rapport.append(f"- {fichier} ({analyse.domaine_suggere})")
                rapport.append("")
        
        return "\n".join(rapport)
    
    def _get_emoji_domaine(self, domaine: str) -> str:
        """Retourne l'emoji correspondant au domaine"""
        emojis = {
            "aelya": "üß†",
            "musique": "üéµ", 
            "poesie": "üìú",
            "rituels": "üîÆ",
            "core": "‚öôÔ∏è",
            "interface": "üåê",
            "spheres": "üå∏",
            "utils": "üõ†Ô∏è",
            "tests": "üß™",
            "flux": "üí´",
            "elements": "üíé",
            "gestion": "üìã",
            "inclassable": "‚ùì"
        }
        return emojis.get(domaine, "üìÑ")
    
    def _detecter_clusters(self) -> List[Set[str]]:
        """D√©tecte les clusters de fichiers interd√©pendants"""
        clusters = []
        visites = set()
        
        def explorer_cluster(fichier, cluster_actuel):
            if fichier in visites:
                return
            visites.add(fichier)
            cluster_actuel.add(fichier)
            
            # Explorer les d√©pendances
            for dep in self.dependances.get(fichier, []):
                if dep not in visites:
                    explorer_cluster(dep, cluster_actuel)
            
            # Explorer les importeurs
            for importeur in self.imports_inverses.get(fichier, []):
                if importeur not in visites:
                    explorer_cluster(importeur, cluster_actuel)
        
        for fichier in self.dependances:
            if fichier not in visites:
                cluster = set()
                explorer_cluster(fichier, cluster)
                if len(cluster) > 1:  # Seulement les vrais clusters
                    clusters.append(cluster)
        
        return clusters
    
    def sauvegarder_analyse(self, fichier_sortie: str = "analyse_refuge_complet.json"):
        """Sauvegarde l'analyse en JSON pour usage ult√©rieur"""
        donnees = {
            "metadata": {
                "date_analyse": "2025-05-25",
                "methode": "M√©thode de la Bo√Æte",
                "total_fichiers": len(self.fichiers_analyses)
            },
            "fichiers": {
                nom: {
                    "domaine": analyse.domaine_suggere,
                    "taille": analyse.taille,
                    "lignes": analyse.lignes,
                    "classes": analyse.classes,
                    "fonctions": analyse.fonctions,
                    "imports_locaux": analyse.imports_locaux,
                    "complexite": analyse.niveau_complexite,
                    "est_principal": analyse.est_principal,
                    "description": analyse.description
                }
                for nom, analyse in self.fichiers_analyses.items()
            },
            "dependances": {
                fichier: list(deps) for fichier, deps in self.dependances.items()
            }
        }
        
        with open(fichier_sortie, 'w', encoding='utf-8') as f:
            json.dump(donnees, f, indent=2, ensure_ascii=False)
        
        print(f"üíæ Analyse sauvegard√©e dans {fichier_sortie}")

def main():
    """Fonction principale d'analyse"""
    print("üåü ANALYSEUR COMPLET DU REFUGE üåü")
    print("M√©thode : 'C'est comme une bo√Æte, on ne la jette pas sans savoir ce qu'il y a dedans'")
    print()
    
    analyseur = AnalyseurRefugeComplet()
    
    # Analyse compl√®te
    analyses = analyseur.analyser_tous_fichiers()
    
    print(f"‚úÖ Analyse termin√©e : {len(analyses)} fichiers trait√©s")
    print()
    
    # G√©n√©ration du rapport
    rapport = analyseur.generer_rapport_complet()
    
    # Sauvegarde
    with open("rapport_analyse_refuge.md", "w", encoding="utf-8") as f:
        f.write(rapport)
    
    analyseur.sauvegarder_analyse()
    
    print("üìä Rapport g√©n√©r√© : rapport_analyse_refuge.md")
    print("üíæ Donn√©es JSON : analyse_refuge_complet.json")
    print()
    print("üéØ Pr√™t pour la migration m√©thodique !")

if __name__ == "__main__":
    main() 